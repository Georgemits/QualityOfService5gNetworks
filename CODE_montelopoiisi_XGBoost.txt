
import pandas as pd
from sklearn.model_selection import GridSearchCV, KFold
from xgboost import XGBClassifier
from sklearn.preprocessing import MinMaxScaler
import shap

# diavasma csv
file_path = 'C:/Users/georg/OneDrive/Desktop/CEID/5g/PROEPEKSERGASIA_EXCEL.csv'
data = pd.read_csv(file_path, delimiter=';', decimal=',')

# Χωρισμός σε χαρακτηριστικά και στόχο
X = data.drop(columns=['User_ID', 'resource allocation'])
y = data['resource allocation']

# Μετατροπή των τιμών της μεταβλητής 'resource allocation' σε ακέραιους αριθμούς
y = y.astype(float).round(0).astype(int)

# Προεπεξεργασία των δεδομένων
# Μετατροπή της ποιοτικής μεταβλητής application type σε δυαδικές μεταβλητές (dummies)
X = pd.get_dummies(X)

# Κλιμακοποίηση των χαρακτηριστικών
scaler = MinMaxScaler()
X = scaler.fit_transform(X)

# Δημιουργία του ταξινομητή XGBoost Classifier
model = XGBClassifier()

# Ορισμός του πλέγματος υπερπαραμέτρων
param_grid = {
    'learning_rate': [0.05, 0.1, 0.2, 0.5, 1],
    'max_depth': [2, 4, 6, 10],
    'min_child_weight': [1, 10, 100, 400],
    'gamma': [0.1, 1, 10, 100],
    'subsample': [0.25, 0.5, 0.75, 1],
    'colsample_bytree': [1/3, 2/3, 1],
}

# Δημιουργία του GridSearchCV
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=KFold(n_splits=10, shuffle=True), verbose=2)

# Εκπαίδευση του μοντέλου
grid_result = grid_search.fit(X, y)

# Εκτύπωση των καλύτερων υπερπαραμέτρων
print("Best Parameters:", grid_result.best_params_)

# Εφαρμογή του SHAP
explainer = shap.Explainer(grid_result.best_estimator_)
shap_values = explainer.shap_values(X)
shap.summary_plot(shap_values, X)
